\documentclass[twocolumn]{article}

\usepackage{algorithm}
\usepackage{algpseudocode}

%----------TEMP
\usepackage{xcolor}
\usepackage{pagecolor}
\pagecolor{white!5!black!95}
\color{white!70!black!30}
%----------/TEMP

\title{A GPU based distributed algorithm for HyperNEAT}
\author{Emad Hosseini \thanks{University of Tehran, 
Department of Algorithms and computation.} 
\and Ali Kamandi}

\begin{document}
\maketitle

%----------------------------------------------------

\section{Introduction}
The advancements in the field AI in the past few decades has led to it being one of the tools of our everyday life. Yet there are some great challenges in developing and training AI systems. There are some tasks that today's AI systems are particularly more capable of doing. That includes image classification \cite{DeepImageClassificationReview}, natural language processing \cite{NLPReview}, motor control \cite{DeepRlforMotorControl} and many other fields that previously seemed impossible for machines to do and were considered specific to humans and animals.

But what made these traits possible is the advancements in computers and hardware that made faster processors and larger memories and with the help of more data scientists could build working AI software. Yet training each model that is capable of a narrow field of tasks takes thousands of hours of CPU time in huge clusters and on sometimes petabytes of data \cite{NEAT-Hardware-IEEE}

Having more data and enough time to process that data is not something to come by easily and in many cases like autonomous navigation in unknown environments or critical decision making for self driving vehicles lack either the data or the time to train conventional neural network models. There are also other challenges including vanishing and exploding gradients \cite{ExplodingAndVanishingGradients}, optimum network structure and other known issues of back propagation that are known to scientists. 

One group of models that tackles these challenges are neuroevolution models. That is defined by Gomez and  Miikkulainen in 1999 as ``systems that evolve neural networks using genetic algorithms'' \cite{NEDefenitionMiikkulainen} and genetic algorithm has some features that makes it ideal for such tasks as training a neural network. These features include no assumptions about the search space and its derivatives, high capability of parallel processing and incremental complexity.

Therefor many research is done in actual models that implement neuroevolution including early works that we mentioned before (\cite{NEDefenitionMiikkulainen}), probabilistic models like \cite{OtherNESample1}, NEAT \cite{originalNEAT} and many others.

Full utilization of any GA means using its distributable capacities and that is the target of this paper.

In this paper we will introduce a computation method for a specific type of NE model i.e. NEAT using general purpose computers. In the next part we see what has already been done in this field and after that in section 3 our computational method is presented. Some benchmarks are done and results are shown in section 4 with conclusions that follows.

%----------------------------------------------------

\section{Background}
Neuroevolution of augmented topologies (NEAT) is one of the most successful models of neuroevolution introduced in 2002 by Stanley and Miikkulainen \cite{originalNEAT} in this model there is an encoding of the neural network in a genotype that considers an innovation number for each newly formed weight. Also different complexity networks are kept separate using a mechanism of speciation to allow each of them excel in their own rival group and avoid new and unfit individuals get consumed by the older and more mature ones.

A population of such genomes and their respective phenotypes is then created. Using genetic algorithm this population is then directs towards better networks that work better to solve the problem at hand.

NEAT is really successful in finding minimal networks for many tasks that are simple enough but when the requirement of the task is more than that, the search space gets big enough that NEAT is inefficient in finding the best networks. This was addressed in another model called HyperNEAT \cite{originalHyperNEAT} that uses underlying symmetries in tasks through a substrate that is essentially a raw initial network.

This substrate is then filled with the connections that are themselves products of another smaller network trained through NEAT algorithm. For example an object detection task would consider the rotation of the target object as a symmetry therefore having a circular substrate leads to automatic consideration of the required symmetry in the task.

The nature of GA involves many simple individuals controlled by an environment that produces the survival of the fittest mechanism for a certain goal. This seems an ideal task for a distributed system. And some researches have already exploited this feature.

for example Such et al. compared using a parallel GPU based and distributed CPU based neuroevolution against other methods of training the network like Q-learning (DQN) and policy gradients (A3C). \cite{GA-GPU-Comparison}

Also the fact that GA can utilize GPU and run more efficient on a distributed systems is not new and many existing research in this field is gathered by Cheng and Gen in their recent review of the field. \cite{GA-GPU-Review}

Using the same methods for getting better results in the HyperNEAT is the target of this paper. There are two main steps in distributing the task of any GA based algorithm the first and easy part is distributing the individuals (which is very important in the case of HyperNEAT as explained in section 3) and the next step is to distribute the control unit that is often called the environment. This part involves each of the separate individuals of the population in the task of finding the fittest and crossover the parents to create child genome replacing them with the less fit individuals.

%----------------------------------------------------

\section{Distributed HyperNEAT}
There are a few words that are used in this paper that we should clarify their meaning before we delve into the algorithm. Every neural network problem has vector of real numbers as it's \textit{input} and another vector is generated as \textit{output}. In HyperNEAT there is an empty network that consists only of nodes with no connections which is called \textit{substrate}. The nodes in the substrate have coordinates and it is defined by the expert considering the symmetries and other features of the problem space as defined by Stanley et al. \cite{originalHyperNEAT}

Generally in the literature the genetic algorithm of NEAT is applied on small neural networks with the task of creating best connections for the substrate but in this paper, for the reason which we will discuss later, an \textit{individual} of the genetic algorithm consists of its own copy of the substrate plus, a NEAT genome.

Each individual in this model is capable of generating output based on an input by creating the genotype of NEAT network filling its substrate and running the input vector through the newly generated ANN.

A collection of individuals create a \textit{population} that runs for many \textit{generation}s. Each generation is done by calculating the performance measure for each individual and replacing the unfit ones with the new offsprings of the fitter ones.

\textit{Offspring}s of a generation is the result of \textit{crossover} and \textit{mutation} of existing individuals, the details of which will be addressed later on.

With this terminology we can write the normal HyperNEAT algorithm as in algorithm \ref{alg:HyperNEAT}.

\begin{algorithm}
    \caption{HyperNEAT Algorithm}
    \label{alg:HyperNEAT}
    \begin{algorithmic}[1]
        \Procedure{Train HyperNEAT}{$Inputs$,$Outputs$}
            \State{$Individuals \gets CreateInitialPopulation()$}
            \For {$GenerationCounts$}
                \For{$Individual \in Individuals$}
                    \State{$TotalError \gets 0$}
                    \For{$i \leftarrow 1,|Inputs|$}
                        \State{$Actual \gets GetOutput(Individual,Inputs[i])$}
                        \State{$Error \gets Actual-Outputs[i]$}
                        \State{$TotalError \gets TotalError+Error^2$}
                    \EndFor
                \State{$Individual.Error \gets TotalError$}
                \EndFor
            \EndFor
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

We don't go into details of some part of the algorithm here because it's outside the scope of this paper. But one part that interests us is shown in algorithm \ref{alg:Individual}

\begin{algorithm}
    \caption{Calculate output for each individual}
    \label{alg:Individual}
    \begin{algorithmic}
        \Procedure{GetOutput}{$Individual$,$Input$}
            \State{$TODO$}
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

Each individual in each cycle has a serries of operations that needs to be addressed.

\begin{enumerate}
    \item Create NEAT phenotype from its genome
    \item Fill substrate with connections based on the output of the phenotype
    \item Calculate the output of the network with respective input
    \item Compare to expected output, if in training phase
\end{enumerate}

\subsection{Thread per Individual}
\subsection{Environment Distribution}

REMEMBER
Random instead of innovation number

%----------------------------------------------------

\section{Comparison of Results}

%----------------------------------------------------

\section{Conclusion}

%----------------------------------------------------

\bibliographystyle{unsrt}
\bibliography{bibiliography}

\end{document}
